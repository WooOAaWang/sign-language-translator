import os
import cv2
import mediapipe as mp
import numpy as np

# ========== ì‚¬ìš©ì ì„¤ì • ==========
root_video_dir = "C:/Users/goodf/Desktop/project/SLV/ëª»ìƒê¸°ë‹¤"  # â— ì‹¤ì œ ì˜ìƒ í´ë” ê²½ë¡œ
label = os.path.basename(root_video_dir)  # ë¼ë²¨ ì´ë¦„ = í´ë”ëª…
save_root = os.path.join('sign_data', label)  # ì €ì¥ ë””ë ‰í† ë¦¬



# MediaPipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
pose = mp_pose.Pose()
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)

# ì˜ìƒ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
video_files = [f for f in os.listdir(root_video_dir) if f.endswith('.mp4')]
print(f"[INFO] ì´ ì˜ìƒ íŒŒì¼ ìˆ˜: {len(video_files)}ê°œ")

for idx, video_file in enumerate(video_files):
    video_path = os.path.join(root_video_dir, video_file)
    video_name = f"video{idx + 1}"
    save_dir = os.path.join(save_root, video_name)
    os.makedirs(save_dir, exist_ok=True)

    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"\nğŸ¥ ì˜ìƒ ì²˜ë¦¬ ì‹œì‘: {video_file} â†’ {video_name} (ì´ í”„ë ˆì„ ìˆ˜: {total_frames})")

    sequence = []
    saved_count = 0
    frame_idx = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret or frame is None:
            print("âš ï¸ í”„ë ˆì„ ì—†ìŒ â€” ì˜ìƒ ë ë˜ëŠ” ì‹¤íŒ¨")
            break

        frame_idx += 1
        print(f"ğŸ“¸ í˜„ì¬ í”„ë ˆì„: {frame_idx}/{total_frames}", end=' | ')

        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        if image is None or image.shape[0] == 0 or image.shape[1] == 0:
            print("âŒ ì´ë¯¸ì§€ shape ì˜¤ë¥˜")
            continue

        image.flags.writeable = False
        pose_result = pose.process(image)
        hands_result = hands.process(image)

        keypoints = []

        # í¬ì¦ˆ
        if pose_result.pose_landmarks:
            for idx in [11, 13, 15, 12, 14, 16]:
                lm = pose_result.pose_landmarks.landmark[idx]
                keypoints.extend([lm.x, lm.y, lm.z])
            print("ğŸ‘¤ í¬ì¦ˆ ì¸ì‹ë¨", end=' | ')
        else:
            keypoints.extend([0] * 18)
            print("ğŸ‘¤ í¬ì¦ˆ ì—†ìŒ", end=' | ')

        # ì†
        if hands_result.multi_hand_landmarks:
            print(f"ğŸ–ï¸ ì† ì¸ì‹: {len(hands_result.multi_hand_landmarks)}ê°œ", end=' | ')
            detected_hands = hands_result.multi_hand_landmarks[:2]
            for hand in detected_hands:
                for lm in hand.landmark:
                    keypoints.extend([lm.x, lm.y, lm.z])
            if len(detected_hands) == 1:
                keypoints.extend([0] * 63)
        else:
            keypoints.extend([0] * 126)
            print("ğŸ–ï¸ ì† ì¸ì‹ ì•ˆë¨", end=' | ')

        if len(keypoints) != 144:
            print("âš ï¸ í‚¤í¬ì¸íŠ¸ ê°œìˆ˜ ì´ìƒ â†’ ê±´ë„ˆëœ€")
            continue

        sequence.append(keypoints)
        print(f"ğŸ§© ì‹œí€€ìŠ¤ ê¸¸ì´: {len(sequence)}/30")

        if len(sequence) == 30:
            np.save(os.path.join(save_dir, f"{saved_count}.npy"), np.array(sequence))
            print(f"âœ… ì €ì¥ë¨: {saved_count}.npy")
            sequence = []
            saved_count += 1

    cap.release()
    print(f"\nğŸ§¾ {video_name} ì €ì¥ ì™„ë£Œ | ì´ ì‹œí€€ìŠ¤: {saved_count}")

cv2.destroyAllWindows()
print("\nğŸ‰ ì „ì²´ ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ")
