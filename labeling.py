import os
import cv2
import mediapipe as mp
import numpy as np

# ========== ì‚¬ìš©ì ì„¤ì • ==========
root_video_dir = "C:/Users/goodf/Desktop/project/SLV/ëª»ìƒê¸°ë‹¤"  # ì‹¤ì œ ì˜ìƒ í´ë” ê²½ë¡œ
label = os.path.basename(root_video_dir)  # ë¼ë²¨ ì´ë¦„ = í´ë”ëª…
save_root = os.path.join('sign_data', label)  # ì‹œí€€ìŠ¤ ì €ì¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ



# MediaPipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
pose = mp_pose.Pose()
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)

# ì˜ìƒ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
video_files = [f for f in os.listdir(root_video_dir) if f.endswith('.mp4')]
print(f"[INFO] ì´ ì˜ìƒ íŒŒì¼ ìˆ˜: {len(video_files)}ê°œ")


#################### ë£¨í”„ ëŒë©´ì„œ ì—¬ëŸ¬íŒŒì¼ ì—¼

for idx, video_file in enumerate(video_files):
    video_path = os.path.join(root_video_dir, video_file)   # ì „ì²´ ì˜ìƒ ê²½ë¡œ
    video_name = f"video{idx + 1}"                          # ì €ì¥ìš© ì˜ìƒ ì´ë¦„(video1, video2 ...)
    save_dir = os.path.join(save_root, video_name)          # ì‹œí€€ìŠ¤ ì €ì¥ ê²½ë¡œë¡œ
    os.makedirs(save_dir, exist_ok=True)

    cap = cv2.VideoCapture(video_path) # ì˜ìƒì—¼ì—¼
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))   # ì´ í”„ë ˆì„ìˆ˜ìˆ˜
    print(f"\nğŸ¥ ì˜ìƒ ì²˜ë¦¬ ì‹œì‘: {video_file} â†’ {video_name} (ì´ í”„ë ˆì„ ìˆ˜: {total_frames})")

    sequence = []   # 30í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì‹œí€€ìŠ¤ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    saved_count = 0 # ì €ì¥ëœ npy íŒŒì¼ ìˆ˜
    frame_idx = 0   # í˜„ì¬ í”„ë ˆì„ ì¸ë±ìŠ¤ìŠ¤

    while cap.isOpened():
        ret, frame = cap.read()     # í”„ë ˆì„ ì½ìŒ
        if not ret or frame is None:
            print(" í”„ë ˆì„ ì—†ìŒ â€” ì˜ìƒ ë ë˜ëŠ” ì‹¤íŒ¨")
            break

        frame_idx += 1
        print(f" í˜„ì¬ í”„ë ˆì„: {frame_idx}/{total_frames}", end=' | ')

        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        if image is None or image.shape[0] == 0 or image.shape[1] == 0:
            print("ì´ë¯¸ì§€ shape ì˜¤ë¥˜")
            continue

        image.flags.writeable = False
        pose_result = pose.process(image)
        hands_result = hands.process(image)

        keypoints = []


        #############################ì—¬ê¸°ëŠ” ì¸ì‹ ì•ˆë˜ëŠ”ê±° ì–´ë””ì„œ ì¸ì‹ ì•ˆë˜ëŠ”ê±°ì§€ ê¶ê¸ˆí•´ì„œ ë„£ì€ë¶€ë¶„ì´ì—¬ì„œ í•„ìš”ëŠ” ì—†ìœ¼
        # í¬ì¦ˆ
        if pose_result.pose_landmarks:
            for idx in [11, 13, 15, 12, 14, 16]:
                lm = pose_result.pose_landmarks.landmark[idx]
                keypoints.extend([lm.x, lm.y, lm.z])
            print("í¬ì¦ˆ ì¸ì‹ë¨", end=' | ')
        else:
            keypoints.extend([0] * 18)
            print("í¬ì¦ˆ ì—†ìŒ", end=' | ')

        # ì†
        if hands_result.multi_hand_landmarks:
            print(f"ì† ì¸ì‹: {len(hands_result.multi_hand_landmarks)}ê°œ", end=' | ')
            detected_hands = hands_result.multi_hand_landmarks[:2]
            for hand in detected_hands:
                for lm in hand.landmark:
                    keypoints.extend([lm.x, lm.y, lm.z])
            if len(detected_hands) == 1:
                keypoints.extend([0] * 63)
        else:
            keypoints.extend([0] * 126)
            print("ì† ì¸ì‹ ì•ˆë¨", end=' | ')

        if len(keypoints) != 144:
            print("í‚¤í¬ì¸íŠ¸ ê°œìˆ˜ ì´ìƒ â†’ ê±´ë„ˆëœ€")
            continue

        sequence.append(keypoints)
        print(f"ì‹œí€€ìŠ¤ ê¸¸ì´: {len(sequence)}/30")

        if len(sequence) == 30:
            np.save(os.path.join(save_dir, f"{saved_count}.npy"), np.array(sequence))
            print(f"ì €ì¥ë¨: {saved_count}.npy")
            sequence = []
            saved_count += 1

    cap.release()
    print(f"\n {video_name} ì €ì¥ ì™„ë£Œ | ì´ ì‹œí€€ìŠ¤: {saved_count}")

cv2.destroyAllWindows()
print("\nì „ì²´ ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ")
