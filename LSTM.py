import os
import numpy as np
import joblib
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dropout
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


# ë°ì´í„° ë° ë¼ë²¨ ë¡œë“œ
def load_data_nested(data_path):
    sequences = []
    sequence_labels = []

    # ë‹¨ì–´ë³„ í´ë” íƒìƒ‰ (ëª»ìƒê¸°ë‹¤, ì˜¤í•´í•´, ...)
    for label in os.listdir(data_path):
        label_path = os.path.join(data_path, label)
        if not os.path.isdir(label_path):  # ì•ˆì „ ì²´í¬
            continue

        # ì˜ìƒë³„ í´ë” íƒìƒ‰ (video1, video2, ...)
        for video_folder in os.listdir(label_path):
            video_path = os.path.join(label_path, video_folder)
            if not os.path.isdir(video_path):
                continue

            # ì‹œí€€ìŠ¤(.npy) íŒŒì¼ ì½ê¸°
            for file in os.listdir(video_path):
                if file.endswith('.npy'):
                    file_path = os.path.join(video_path, file)
                    sequence = np.load(file_path)
                    if sequence.shape == (30, 144):
                        sequences.append(sequence)
                        sequence_labels.append(label)

    return np.array(sequences), sequence_labels


# ëª¨ë¸ ì •ì˜ ë° ì»´íŒŒì¼
def build_model(input_shape, num_classes, num_units, num_layers=2, dropout_rate=0.5):
    model = Sequential()
    # ì²« ë²ˆì§¸ LSTM ì¸µ
    model.add(LSTM(num_units, return_sequences=True if num_layers > 1 else False, input_shape=input_shape))
    # ì¶”ê°€ LSTM ì¸µ
    for i in range(1, num_layers):
        model.add(LSTM(num_units, return_sequences=True if i < num_layers - 1 else False))
        if dropout_rate > 0:
            model.add(Dropout(dropout_rate))
    # Dense ì¸µ
    model.add(Dense(num_units // 2, activation='relu'))
    # ì¶œë ¥ ì¸µ
    model.add(Dense(num_classes, activation='softmax'))
    
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model


# í•™ìŠµ ë° í‰ê°€
def train_and_evaluate(X_train, y_train, X_test, y_test, model):
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), callbacks=[early_stopping])
    
    # ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€
    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)
    
    accuracy = accuracy_score(y_true_classes, y_pred_classes)
    precision = precision_score(y_true_classes, y_pred_classes, average='macro')
    recall = recall_score(y_true_classes, y_pred_classes, average='macro')
    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')
    
    return history, accuracy, precision, recall, f1

# ë©”ì¸í•¨ìˆ˜
def main():
    DATA_PATH = 'sign_data'  # ë°ì´í„°ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ì˜ ê²½ë¡œë¥¼ ì •ì˜
    X, y_labels = load_data_nested(DATA_PATH)    # ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
    le = LabelEncoder()  # ë¼ë²¨ ì¸ì½”ë” ìƒì„±
    y = le.fit_transform(y_labels)  # ë¬¸ìì—´ ë¼ë²¨ì„ ì •ìˆ˜ë¡œ ë³€í™˜
    y_cat = to_categorical(y)  # ì •ìˆ˜ ë¼ë²¨ì„ ì›-í•« ì¸ì½”ë”©


    joblib.dump(le, 'label_encoder.pkl')
    print("ğŸ“¦ ë¼ë²¨ ì¸ì½”ë” ì €ì¥ ì™„ë£Œ â†’ label_encoder.pkl")
    
    # stratify ì˜µì…˜ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ 8:2 ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_cat, test_size=0.2, random_state=42, stratify=y)
    
    num_classes = len(np.unique(y_labels))  # í´ë˜ìŠ¤ ìˆ˜ ê³„ì‚°


    # ì‹¤í—˜í•  íŒŒë¼ë¯¸í„° ìˆ˜ë‘  LSTM ì¸µì˜ ìˆ˜ì™€ ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ì„ ì„¤ì •
    unit_options = [64, 128]   
    num_layers_options = [1, 2]  # LSTM ì¸µì˜ ìˆ˜ë¥¼ ë‹¤ì–‘í•˜ê²Œ ì„¤ì • 1,2,3
    dropout_options = [0, 0.25]  # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ì„ ë‹¤ì–‘í•˜ê²Œ ì„¤ì • 0, 0.25, 0.5
    

    # ê° ì¡°í•©ì— ëŒ€í•´ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  í‰ê°€
    for num_units in unit_options:
        for num_layers in num_layers_options:
            for dropout_rate in dropout_options:
                print(f"\n Training with {num_units} units, {num_layers} layers, dropout {dropout_rate}")
                model = build_model((30, 144), num_classes, num_units, num_layers, dropout_rate)
                history, accuracy, precision, recall, f1 = train_and_evaluate(X_train, y_train, X_test, y_test, model)

                print(f" Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}")
# ì¶œë ¥ì€ ê° íŒŒë¦¬ë¯¸í„° ìˆ˜ ë³„ ê° LSTMì¸µ ë³„ ê° dropoutë¹„ìœ¨ë³„ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì´ ì¶œë ¥ë¨ë¨

                model_name = f"sign_model_u{num_units}_l{num_layers}_d{int(dropout_rate*100)}.h5"
                model.save(model_name)
                print(f"ğŸ“¦ ëª¨ë¸ ì €ì¥ ì™„ë£Œ â†’ {model_name}")



if __name__ == "__main__":
    main()
